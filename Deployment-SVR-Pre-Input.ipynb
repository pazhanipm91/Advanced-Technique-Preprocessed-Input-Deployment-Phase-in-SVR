{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a50c43b-fde2-4c45-9b16-35c38c9dc14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56aabe70-ac02-470e-bc89-c7c67c810ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # These 3 steps is going to be applied for only preprocessing techniques in deploymnet phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589526b4-aaeb-4982-be42-8dd7883f6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"50_Startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882bdf6b-9ac9-47f5-a124-d305e044671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical data into numerical data\n",
    "dataset=pd.get_dummies(dataset,drop_first=True)\n",
    "independent=dataset[['R&D Spend', 'Administration', 'Marketing Spend', 'State_Florida', 'State_New York']]\n",
    "dependent=dataset[[\"Profit\"]]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent,dependent, test_size = 0.30,random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ff1f6e-fe33-4320-8645-59734a04b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization Technique: THis technique will be used only after the the result is not nearly to 1.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train) # Importance of Fit_Transform = All Data's from the X_train going to be applied in the StandardScaler formula & \n",
    "#Substituted the same data in to the (X-Tain) \n",
    "# E.g FIT()= x-mean-value/StandardDeviations = x-10/20.\n",
    "# Fit() methods formula will be applied for the X_train Values and stored to the X_train itself and again Substitues each values from X_train and finally will transform an output.\n",
    "#This routine process is called fit() Transform method.\n",
    "\n",
    "X_test=sc.transform(X_test) #After this execution with this formula \"X-Mue/sigma\" again it'll save the calculation in X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23672f18-8b9f-4a74-82a7-a1bb0e5edb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preinput=sc.transform([[1300,12000,4000,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4689b979-0cc0-4f11-8338-d30966a43a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.46755353, -2.06765439, -1.50741831, -0.5       ,  1.30088727]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fac0e9c1-d4e2-4362-b5be-5381c4522ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open(\"finalized_model_svr.sav\",'rb'))\n",
    "result=loaded_model.predict(preinput) # Pre-processed input going to be passed in the PREDICT() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d6f063d-4748-4321-b344-3228a63c8140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([78556.2609937])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3e10c82-15b1-4fe7-8608-c91c36258340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got the model as pre-processed input and saved in the file. \n",
    "#Incase we got the result [-1. something] = Before Pre-Processed one, Then we have to Re-run all the codes from starting to end. \n",
    "# Then we will get the exact output as Pre-Processed one and will save the model in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa346cf0-ef69-4ffc-989b-73095c06cd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
